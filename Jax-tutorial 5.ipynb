{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b31152c7-dc63-4524-a421-3bd8fc1acda3",
   "metadata": {},
   "source": [
    "# Jax入坑指南系列(五): flax神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d175d4-a86a-44c3-aee9-dc5f5f2dd8c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "在之前的系列里，我们介绍了jax的基本语法框架，并展示了如何用原生态的jax搭建一个MLP神经网络框架来解决mnist手写数字图片的多分类问题。\n",
    "\n",
    "我们继续jax的科学计算之旅并介绍**flax**: flax是基于jax生态的神经网络框架: 类似于pytorch or tensorflow。\n",
    "可以看到越来越多fancy的项目中，如蛋白质结构预测，强化学习，量化交易,还有各类GPT项目采用flax的神经网络框架。其主要原因在于flax相较于上述两个框架的优势:\n",
    "\n",
    "    计算效率(computational efficiency):相比pytorch, tensorflow, flax在计算效率上有着诸多的优势。\n",
    "    可移植性:基于jax的框架可以很容易迁移至如GPU,TPU和其他类型的设备中。\n",
    "    可复现性(reproducibility): 前面我们介绍了对于jax中的随机数生成机制，我们需要显式地对函数或类赋予states, 这使得基于jax与flax的神经网络项目在不现的设备可以更好地复现。 \n",
    "\n",
    "下图是HuggingFace 团队在基准NLP任务测试的一个时效比较(flax vs pytorch):\n",
    "\n",
    "在今天的文章里，我们将展示:\n",
    "\n",
    "   1. 基本flax神经网络范式。\n",
    "   2. flax神经网络框架。\n",
    "   3. 使用optax优化求解器包。\n",
    "\n",
    "更多关于flax的应用案例可参见Github官网链接:https://github.com/google/flax/tree/main/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83ae9666-6734-47f3-bc2f-b076a7ad1865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optax==0.1.7 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (0.1.7)\n",
      "Requirement already satisfied: flax in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (0.7.2)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from optax==0.1.7) (1.4.0)\n",
      "Requirement already satisfied: chex>=0.1.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from optax==0.1.7) (0.1.7)\n",
      "Requirement already satisfied: jax>=0.1.55 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from optax==0.1.7) (0.4.13)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from optax==0.1.7) (0.4.12)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from optax==0.1.7) (1.24.4)\n",
      "Requirement already satisfied: msgpack in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from flax) (1.0.8)\n",
      "Requirement already satisfied: orbax-checkpoint in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from flax) (0.2.3)\n",
      "Requirement already satisfied: tensorstore in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from flax) (0.1.45)\n",
      "Requirement already satisfied: rich>=11.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from flax) (13.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from flax) (4.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from flax) (6.0)\n",
      "Requirement already satisfied: dm-tree>=0.1.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from chex>=0.1.5->optax==0.1.7) (0.1.8)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from chex>=0.1.5->optax==0.1.7) (0.12.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from jax>=0.1.55->optax==0.1.7) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from jax>=0.1.55->optax==0.1.7) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from jax>=0.1.55->optax==0.1.7) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from jax>=0.1.55->optax==0.1.7) (6.8.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from rich>=11.1->flax) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from rich>=11.1->flax) (2.16.1)\n",
      "Requirement already satisfied: cached_property in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from orbax-checkpoint->flax) (1.5.2)\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from orbax-checkpoint->flax) (6.0.1)\n",
      "Requirement already satisfied: etils in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from orbax-checkpoint->flax) (1.3.0)\n",
      "Requirement already satisfied: nest_asyncio in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from orbax-checkpoint->flax) (1.5.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax>=0.1.55->optax==0.1.7) (3.16.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install optax==0.1.7 flax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a95e0a2-1e73-40a0-b168-4c8cad3ea935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python libs\n",
    "import functools  # useful utilities for functional programs\n",
    "from typing import Any, Callable, Sequence, Optional\n",
    "\n",
    "# Other important 3rd party libs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "from jax import lax, jit, random, numpy as jnp\n",
    "\n",
    "# JAX optimizers - a separate lib developed by DeepMind\n",
    "import optax\n",
    "\n",
    "# NN lib built on top of JAX developed by Google Research (Brain team)\n",
    "# Flax was \"designed for flexibility\" hence the name (Flexibility + JAX -> Flax)\n",
    "import flax\n",
    "from flax.core import freeze, unfreeze\n",
    "from flax.training import train_state "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad072f-77df-4749-86d3-dd87fee530ea",
   "metadata": {},
   "source": [
    "## flax神经网络框架\n",
    "### Recap: jax神经网络 \n",
    "在前面我们实现了一个pure-jax的用于mnist多分类的多层感知机(MLP:multi-layer perceptron)模型框架。\n",
    "对于mnist数据集，我们原始的图片的输入维度是是$1\\times 784$,要预测是10个数据类型的概率，相应地，我们可以搭建一个层数分别为[784,512,256,10]的MLP模型框架,用jax代码表示:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "12fd69e7-dcac-47d1-936b-fec0d941f1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from scipy.special import logsumexp\n",
    "from jax.scipy.special import logsumexp\n",
    "def MLP_predict(params, x):\n",
    "    hidden_layers = params[:-1]\n",
    "    activation = x\n",
    "    for w,b in hidden_layers:\n",
    "        activation = jax.nn.relu(jnp.dot(w,activation)+b)\n",
    "\n",
    "    #在最后一层，我们不想使用relu激活函数\n",
    "    w_last,b_last = params[-1]\n",
    "    logits = jnp.dot(w_last, activation)+b_last\n",
    "    \n",
    "    return  logits - logsumexp(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555bf93-bea4-467a-8d1f-ec28c5f40b71",
   "metadata": {},
   "source": [
    "在最后预测输出部分，我们通过log-sum-exp trick实现了交叉熵损失(cross-entropy loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aab64f73-6c28-4b0e-aa34-5e9939150029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed=0\n",
    "key = jax.random.PRNGKey(seed)\n",
    "MLP_params = init_MLP([784, 512, 256, 10],key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfb4b6f-9bc8-43be-a1ff-a1fe4964bda7",
   "metadata": {},
   "source": [
    "在上述中jax实现版本中:\n",
    "   1. 我们用for-loop生成随机矩阵list作为神经网络的参数列表。\n",
    "   2. 我们简单对随机生成的参数进行缩放( *0.01)以避免训练过程中的梯度爆炸(Gradient explosion)。\n",
    "   3. jax中需要显式地赋予状态变量。对于一个MLP模型，每一层layer我们都需要显式地赋予一个状态变量，我们通过之前介绍的random.split的机制实现。\n",
    "\n",
    "我们用flax对上述代码框架进行迭代改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e301e-8fb6-4a86-bcfd-6c69ffe5a285",
   "metadata": {},
   "source": [
    "上述中的每一层我们都用一个权重矩阵$m \\times n$的权重矩阵$W, W \\in \\mathbb{R}^{m \\times n } $，\n",
    "和一个$m$维的bias向量, 其中$n$是每一层输入的维度, $m$是输出的维度, 整个映射用公式表式则是\n",
    "$\n",
    "Wx+b\n",
    "$\n",
    ",上述逻辑在flax中我们可以用***flaxlinen**模块表示, 如对于最后一层layer,我们可以用如下代码表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a93ff423-9512-4fac-be8a-7185cab6c1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense(\n",
      "    # attributes\n",
      "    features = 10\n",
      "    use_bias = True\n",
      "    dtype = None\n",
      "    param_dtype = float32\n",
      "    precision = None\n",
      "    kernel_init = init\n",
      "    bias_init = zeros\n",
      "    dot_general = dot_general\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from flax import linen as nn \n",
    "#a single feed-forward layer (linear regression)\n",
    "final_layer = nn.Dense(features=10)\n",
    "print(final_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790139cf-6333-43d4-943d-cfdb97a8a00d",
   "metadata": {},
   "source": [
    "上述代码中，我们通过nn.Dense实现了一个输出维度为10维，包含Weight与bias的dense layer; "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9be991-423e-486b-bce6-abd1bca70e0e",
   "metadata": {},
   "source": [
    "### flax神经网络范式\n",
    "在用flax重现上述网络前，我们先设计一个仅包含一层layer的flax网络模型,来更好地描述flax神经网络的范式。\n",
    " 如对于一个电商平台上的商品，我们希望预测其下一周的总销量，我们可能有的features有(下一周我们设定的价格price, 上周平均销量lag_avg_sales),总共2个features. 假设我们有历史N周的训练数据，用公式表式:  . 我们可以单层dense layer表示这样一个线性回归模型。用flax的nn.Dense表示:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3164eea-a6d8-41a6-a2e4-2814a7b989f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = nn.Dense(features=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe26d2f-3cee-4370-bb88-0e0f02cf48d4",
   "metadata": {},
   "source": [
    "在flax框架中 ,一个通用的神经网络的执行，包含两个步骤:\n",
    "\n",
    "    1. 初始化(init): 初始化神经网络的参数值集合，可以是基于梯度下降的方法找到的更优的参数集。\n",
    "    2. 应用(apply): 通过类似函数式编程里apply的方式实现预测(矩阵乘积的方式)。\n",
    "\n",
    "下面是一个简单案例实现:\n",
    "\n",
    "**初始化random state**: 通过split初始化两个key: key1与key2: key1主要用于测试样本的生成，假定有100个测试样本(n=100); key2主要用于模型权重参数的random state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a602032d-82bb-4b1b-8df6-5e5c85ed3e43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 23\n",
    "key1, key2 = random.split(random.PRNGKey(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa98d42b-b8e2-41af-b208-eeb62de127e3",
   "metadata": {},
   "source": [
    "生成随机样本:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a232fea-23c0-4ca0-851b-4ef1d2a0b326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 生成100个随机样本:\n",
    "x = random.normal(key1, (100,3))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d670311-4349-4501-b728-15b8dcc6dbb2",
   "metadata": {},
   "source": [
    "用key2初始化并随机生成真实的权重(weight)与偏差项(bias term):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "62108a55-3843-490f-8e44-1b508ce2abdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.1452696 ]\n",
      " [ 0.47438544]\n",
      " [ 0.8055905 ]\n",
      " [-1.2088227 ]\n",
      " [ 0.5021587 ]\n",
      " [-3.9167035 ]\n",
      " [-0.3753886 ]\n",
      " [ 0.8991089 ]\n",
      " [-1.7313836 ]\n",
      " [-0.77858627]\n",
      " [ 1.8731394 ]\n",
      " [-0.01683131]\n",
      " [-0.11122859]\n",
      " [-0.57577986]\n",
      " [ 1.9738257 ]\n",
      " [-0.4151314 ]\n",
      " [-0.9655249 ]\n",
      " [ 0.97407067]\n",
      " [-1.3242964 ]\n",
      " [ 0.77407944]\n",
      " [ 1.2942377 ]\n",
      " [-1.648177  ]\n",
      " [ 2.167247  ]\n",
      " [ 1.0109514 ]\n",
      " [-0.9501833 ]\n",
      " [ 0.06982961]\n",
      " [-0.88490117]\n",
      " [-0.01005059]\n",
      " [ 0.9263705 ]\n",
      " [-3.1054764 ]\n",
      " [-0.26195604]\n",
      " [-1.809225  ]\n",
      " [-1.4962196 ]\n",
      " [ 0.83810556]\n",
      " [ 0.49551037]\n",
      " [ 1.3626446 ]\n",
      " [-0.7285978 ]\n",
      " [ 0.98932475]\n",
      " [-0.1772615 ]\n",
      " [ 1.674576  ]\n",
      " [-3.4050255 ]\n",
      " [-0.10310718]\n",
      " [ 1.5714715 ]\n",
      " [ 1.3523289 ]\n",
      " [ 2.238317  ]\n",
      " [ 0.673101  ]\n",
      " [-1.7060467 ]\n",
      " [-1.6703906 ]\n",
      " [ 2.321227  ]\n",
      " [ 2.963707  ]\n",
      " [ 0.954055  ]\n",
      " [ 0.64043653]\n",
      " [ 2.0067015 ]\n",
      " [-2.6782627 ]\n",
      " [-3.420617  ]\n",
      " [ 0.8893894 ]\n",
      " [ 0.8665298 ]\n",
      " [ 2.9253101 ]\n",
      " [-1.7252162 ]\n",
      " [-1.7834357 ]\n",
      " [ 1.437428  ]\n",
      " [-0.14989647]\n",
      " [ 1.3315102 ]\n",
      " [-0.41053534]\n",
      " [-0.18336205]\n",
      " [ 0.9523465 ]\n",
      " [ 0.26633865]\n",
      " [-0.30575517]\n",
      " [ 3.5061617 ]\n",
      " [-2.4886081 ]\n",
      " [ 1.326208  ]\n",
      " [ 0.89195186]\n",
      " [-3.1564207 ]\n",
      " [ 0.14913955]\n",
      " [-1.7235205 ]\n",
      " [ 0.8620045 ]\n",
      " [-0.33627698]\n",
      " [-0.30710724]\n",
      " [-1.0573289 ]\n",
      " [ 0.21180008]\n",
      " [-0.39231908]\n",
      " [ 0.17183886]\n",
      " [-0.7237001 ]\n",
      " [ 0.04940411]\n",
      " [ 0.10195032]\n",
      " [-1.9836011 ]\n",
      " [-0.55133164]\n",
      " [-1.0324306 ]\n",
      " [-1.4345641 ]\n",
      " [-2.436304  ]\n",
      " [ 3.4937117 ]\n",
      " [-0.29717737]\n",
      " [ 0.6129105 ]\n",
      " [-0.42901957]\n",
      " [-2.3462167 ]\n",
      " [ 1.3609155 ]\n",
      " [ 1.2037365 ]\n",
      " [-1.0890677 ]\n",
      " [-0.38550586]\n",
      " [ 1.5571177 ]]\n",
      "{'params': {'kernel': Array([[-1.0700977 ],\n",
      "       [-0.8896222 ],\n",
      "       [-0.21253328]], dtype=float32), 'bias': Array([0.], dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "# 用key2初始化模型的参数\n",
    "y, params = model.init_with_output(key2, x)  \n",
    "print(y); print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142f0ebe-b4d1-449e-98a3-34b7e44a144c",
   "metadata": {},
   "source": [
    "从params打印的结果，我们可以看到，flax能自动对输入的shape进行inference;同样的，我们可以用jax.tree_map对其进行打印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22b35ce7-3756-4653-a9f8-109e0e0d14c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': {'bias': (1,), 'kernel': (3, 1)}}\n"
     ]
    }
   ],
   "source": [
    "print(jax.tree_map(lambda x: x.shape, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01bb946-5d62-495c-9427-49d2832fd53e",
   "metadata": {},
   "source": [
    "在pytorch中，给定一个模型model与输入x，可以直接通过model(x)的方式输出预测结果，但在flax我们需要严格使用apply的方式,即:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed01ef20-ea3e-48a1-966e-d79d90177e9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: apply\n",
    "y = model.apply(params, x)  # this is how you run prediction in Flax, state is external!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a3f211-fcac-415d-8a21-71cc04c5743e",
   "metadata": {},
   "source": [
    "若使用model(x)的方式，将报错:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4e9f57d5-19db-4283-a504-d8e368215aec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't call compact methods on unbound modules (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.CallCompactUnboundModuleError)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    y = model(x)  # this doesn't work anymore (bye bye PyTorch syntax)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72788f2-a3cd-44e9-8f06-7ee583a648b2",
   "metadata": {},
   "source": [
    "## 自定义模型: custom model\n",
    "回到先前我们的MLP框架， 和pytorch中类似，在flax中, 我们可以用nn.Module包含多个nn.Dense定制成一个模型类将上述代码用flax的方式实现:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6a8befd7-86e5-444d-a289-b80f3b995519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class flaxMLP(nn.Module):\n",
    "    features: Sequence[int]\n",
    "    \n",
    "    def setup(self):\n",
    "        self.layers = [nn.Dense(feat) for feat in self.features]\n",
    "        #如果只有一层layer\n",
    "        #self.layer1 = nn.Dense(feat1)\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for i, lyr in enumerate(self.layers):\n",
    "            x = lyr(x)\n",
    "            if i != len(self.layers) - 1:\n",
    "                x = nn.relu(x)\n",
    "        x = nn.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ddbabf-f0aa-4e20-9dea-e25a57d91bff",
   "metadata": {},
   "source": [
    "在上述代码中:\n",
    "   1. 和其他神经网络框架类似, nn.Module是一个dataclass类，在nn.Module，我们定义了Sequence类型的features用来代表每一层layer output的features\n",
    "   2. setup是一个注册函数，我们在setup中定义我们在模型中需要的变量(variable)，参数(parameters), 子模块(submodule).\n",
    "   3.  __call__函数类似pytorch中的forward:给定输入，返回模型的输出。\n",
    "   4. 在模型中我们定义了pytree结构的参数集:pytree结构的参数每层包含一个Layers_n子字典，每个子字典都包含关联的Dense层的参数。\n",
    "   5. 在最后一层的nn.log_softmax其等价于之前介绍的log-sum-sofmax trick实现的逻辑。\n",
    "   \n",
    "   \n",
    "同样地:我们可以初始化两个key: key1与key2:\n",
    "  1. 通过key1,生成一个batch(16*784)的图片仿真数据\n",
    "  2. key2用来初始化模型的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ab3aaa77-a5f9-473b-9ef8-9619608c0c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2 = random.split(random.PRNGKey(0), 2)\n",
    "x = random.uniform(key1, (128,784))\n",
    "\n",
    "model = flaxMLP(features=[784, 512, 256, 10])\n",
    "y, params = model.init_with_output(key2, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f76816-de18-46b8-860e-10ba8ee48538",
   "metadata": {
    "tags": []
   },
   "source": [
    "用jax.tree_map打印参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "db85ae79-2fbc-4cfb-a0f9-a318d00d506c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'layers_0': {'bias': (784,), 'kernel': (128, 784)},\n",
       "  'layers_1': {'bias': (512,), 'kernel': (784, 512)},\n",
       "  'layers_2': {'bias': (256,), 'kernel': (512, 256)},\n",
       "  'layers_3': {'bias': (10,), 'kernel': (256, 10)}}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#用jax.tree_map打印参数\n",
    "jax.tree_map(lambda x: x.shape, params) # Checking output shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4908d56b-875a-4be9-a1fd-f8d4e50f7ba3",
   "metadata": {
    "tags": []
   },
   "source": [
    "用model.tabulate方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71b31be0-d39b-4cd2-8d5a-4db777a8e474",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[3m                                flaxMLP Summary                                \u001b[0m\n",
      "┏━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
      "┃\u001b[1m \u001b[0m\u001b[1mpath    \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                  \u001b[0m\u001b[1m \u001b[0m┃\n",
      "┡━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
      "│          │ flaxMLP │ \u001b[2mfloat32\u001b[0m[128] │ \u001b[2mfloat32\u001b[0m[10]  │                          │\n",
      "├──────────┼─────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ layers_0 │ Dense   │ \u001b[2mfloat32\u001b[0m[128] │ \u001b[2mfloat32\u001b[0m[784] │ bias: \u001b[2mfloat32\u001b[0m[784]       │\n",
      "│          │         │              │              │ kernel: \u001b[2mfloat32\u001b[0m[128,784] │\n",
      "│          │         │              │              │                          │\n",
      "│          │         │              │              │ \u001b[1m101,136 \u001b[0m\u001b[1;2m(404.5 KB)\u001b[0m       │\n",
      "├──────────┼─────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ layers_1 │ Dense   │ \u001b[2mfloat32\u001b[0m[784] │ \u001b[2mfloat32\u001b[0m[512] │ bias: \u001b[2mfloat32\u001b[0m[512]       │\n",
      "│          │         │              │              │ kernel: \u001b[2mfloat32\u001b[0m[784,512] │\n",
      "│          │         │              │              │                          │\n",
      "│          │         │              │              │ \u001b[1m401,920 \u001b[0m\u001b[1;2m(1.6 MB)\u001b[0m         │\n",
      "├──────────┼─────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ layers_2 │ Dense   │ \u001b[2mfloat32\u001b[0m[512] │ \u001b[2mfloat32\u001b[0m[256] │ bias: \u001b[2mfloat32\u001b[0m[256]       │\n",
      "│          │         │              │              │ kernel: \u001b[2mfloat32\u001b[0m[512,256] │\n",
      "│          │         │              │              │                          │\n",
      "│          │         │              │              │ \u001b[1m131,328 \u001b[0m\u001b[1;2m(525.3 KB)\u001b[0m       │\n",
      "├──────────┼─────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│ layers_3 │ Dense   │ \u001b[2mfloat32\u001b[0m[256] │ \u001b[2mfloat32\u001b[0m[10]  │ bias: \u001b[2mfloat32\u001b[0m[10]        │\n",
      "│          │         │              │              │ kernel: \u001b[2mfloat32\u001b[0m[256,10]  │\n",
      "│          │         │              │              │                          │\n",
      "│          │         │              │              │ \u001b[1m2,570 \u001b[0m\u001b[1;2m(10.3 KB)\u001b[0m          │\n",
      "├──────────┼─────────┼──────────────┼──────────────┼──────────────────────────┤\n",
      "│\u001b[1m \u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m       Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m636,954 \u001b[0m\u001b[1;2m(2.5 MB)\u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0m│\n",
      "└──────────┴─────────┴──────────────┴──────────────┴──────────────────────────┘\n",
      "\u001b[1m                                                                               \u001b[0m\n",
      "\u001b[1m                      Total Parameters: 636,954 \u001b[0m\u001b[1;2m(2.5 MB)\u001b[0m\u001b[1m                       \u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.tabulate(jax.random.PRNGKey(0), x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9040848-0c2a-401c-a80d-9396ae613878",
   "metadata": {},
   "source": [
    "上述我们使用了setup函数来定义函数变量与子模块; 我们可以用@nn.compact的方式将set_up函数中定义好的放入至__call__里对其进行优化，使其代码更加简洁:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d64def7d-23d9-4d66-a464-b067b9b93f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class flaxMLP2(nn.Module):\n",
    "    features: Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for i, feat in enumerate(self.features):\n",
    "            x = nn.Dense(feat, name=f'layers_{i}')(x)\n",
    "            if i != len(self.features) - 1:\n",
    "                x = nn.relu(x)\n",
    "        x = nn.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae17b11-42b4-4031-964e-d1ee53ce4872",
   "metadata": {},
   "source": [
    "## optax: 梯度下降优化\n",
    "在前面，我们通过手撸的方式自定义损失函数(loss function)与准确度(accuracy)，并用jax.tree_map组织参数集合(pytree格式)完成了梯度下降:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8c1e07b1-3a63-4074-a6af-b0304a99d458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# np.ravel: flatten the image 将28x28转成(784,)的一维数据\n",
    "def custom_transform(x):\n",
    "    return np.ravel(np.array(x, dtype=np.float32))\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    transposed_data = list(zip(*batch))\n",
    "\n",
    "    labels = np.array(transposed_data[1])\n",
    "    imgs = np.stack(transposed_data[0])\n",
    "\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "#训练集\n",
    "train_dataset = MNIST('train_mnist',train=True,download=True,transform=custom_transform)\n",
    "#测试集\n",
    "test_dataset = MNIST('test_mnist', train=False,download=True,transform=custom_transform)\n",
    "\n",
    "batch_size=128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, collate_fn=custom_collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "64128f88-a568-4f60-b321-b69baeef7602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transfer the data to jnp\n",
    "# optimization - loading the whole dataset into memory\n",
    "train_images = jnp.array(train_dataset.data).reshape(len(train_dataset), -1)\n",
    "train_lbls = jnp.array(train_dataset.targets)\n",
    "\n",
    "test_images = jnp.array(test_dataset.data).reshape(len(test_dataset), -1)\n",
    "test_lbls = jnp.array(test_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "862286cd-f0c2-4018-9b32-9c8c52a19e01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), array([4, 1, 6, 0, 7, 9, 3, 2, 2, 8, 1, 8, 9, 5, 6, 1, 6, 0, 6, 6, 6, 1,\n",
      "       9, 2, 1, 6, 0, 4, 3, 8, 1, 1, 4, 8, 1, 5, 1, 4, 8, 0, 0, 9, 7, 8,\n",
      "       6, 4, 7, 7, 6, 3, 8, 6, 7, 2, 2, 3, 2, 3, 1, 5, 4, 3, 6, 8, 0, 9,\n",
      "       5, 8, 1, 7, 0, 7, 4, 5, 4, 8, 2, 4, 8, 2, 1, 7, 5, 6, 4, 7, 7, 9,\n",
      "       4, 9, 2, 6, 7, 8, 0, 5, 9, 5, 0, 4, 7, 7, 3, 7, 4, 1, 1, 8, 0, 6,\n",
      "       9, 9, 2, 0, 7, 6, 6, 5, 1, 0, 5, 7, 1, 6, 2, 5, 1, 2]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data = next(iter(train_loader))\n",
    "print(batch_data)\n",
    "type(batch_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "345782a3-0681-4602-9673-8e4ee22d2e35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(params, imgs, gt_lbls):\n",
    "    predictions = model.apply(params, imgs)\n",
    "    return -jnp.mean(predictions * gt_lbls)\n",
    "\n",
    "def accuracy(params, dataset_imgs, dataset_lbls):\n",
    "    pred_classes = jnp.argmax(model.apply(params, dataset_imgs), axis=1)\n",
    "    return jnp.mean(dataset_lbls == pred_classes)\n",
    "\n",
    "@jit\n",
    "def update(params, imgs, gt_lbls, lr=0.01):\n",
    "    loss, grads = value_and_grad(loss_fn)(params, imgs, gt_lbls)\n",
    "    return loss, jax.tree_map(lambda p, g: p - lr*g, params, grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee240b-9acf-4347-9d74-b99777f9e902",
   "metadata": {},
   "source": [
    "但在更复杂的神经网络中，我们可能需要自适应的优化求解器来寻找我们的最优参数集，如momentum, adagrad, adam等等, 在jax中我们可以尝试用optax包, optax是JAX的梯度处理与优化库(a gradient processing and optimization library for JAX): https://optax.readthedocs.io/en/latest/\n",
    "一个optax使用流程可以如下表示:\n",
    "   1. 选择一类优化方法(optimization method)\n",
    "   2. 通过参数创建优化器的状态(state)。\n",
    "   3. 通过jax.value_and_grad计算每次迭代的梯度(gradient)\n",
    "   4. 在每次迭代中，我们通过Optax同时更新优化器状态与模型参数，然后使用通过apply_updates 方法将其添加至参数中。\n",
    "  \n",
    "如对应于上述的手工sgd算法逻辑:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cf71d7-2fc1-4c12-8774-17a7a38268da",
   "metadata": {
    "tags": []
   },
   "source": [
    "我们用optax代替原有的梯度下降逻辑:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2a13fc69-4efb-45de-ae17-66754c6870f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "x1 = random.uniform(key1, (128,784))*0.01\n",
    "\n",
    "model = flaxMLP2([784, 512, 256, 10])\n",
    "y, params = model.init_with_output(key2, x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "25e444cf-b297-44af-bed2-5b18e228ba32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'layers_0': {'bias': (784,), 'kernel': (784, 784)},\n",
       "  'layers_1': {'bias': (512,), 'kernel': (784, 512)},\n",
       "  'layers_2': {'bias': (256,), 'kernel': (512, 256)},\n",
       "  'layers_3': {'bias': (10,), 'kernel': (256, 10)}}}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(lambda x: x.shape, params) # Checking output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "46bd7cda-3ff6-4122-8e21-3a7311e9cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def loss_fn(params, imgs, gt_lbls):\n",
    "    predictions = model.apply(params, imgs)\n",
    "    return -jnp.mean(predictions * gt_lbls)\n",
    "\n",
    "opt_sgd = optax.adam(learning_rate=0.001)\n",
    "opt_state = opt_sgd.init(params)  # always the same pattern - handling state externally\n",
    "loss_grad_fn = jax.value_and_grad(loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9253a8f9-7e45-4b88-b0b6-f4d15d34a35a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss step 0:  0.010183704\n",
      "Loss step 50:  0.004264328\n",
      "Loss step 100:  0.0057922844\n",
      "Loss step 150:  0.0072064693\n",
      "Loss step 200:  0.003270747\n",
      "Loss step 250:  0.0012936728\n",
      "Loss step 300:  0.03163723\n",
      "Loss step 350:  0.0021991376\n",
      "Loss step 400:  0.008238067\n",
      "Loss step 450:  0.020124018\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for cnt, (imgs, lbls) in enumerate(train_loader):\n",
    "        gt_labels = jax.nn.one_hot(lbls, len(MNIST.classes))\n",
    "        loss_val, grads = loss_grad_fn(params, imgs, gt_labels)\n",
    "        updates, opt_state = opt_sgd.update(grads, opt_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        if cnt % 50 == 0:\n",
    "            print('Loss step {}: '.format(cnt), loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4430f7aa-b8b3-45d1-b54b-76271f643bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "pred 9\n",
      "get 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs, lbls = next(iter(test_loader))\n",
    "img = imgs[0]#.reshape(mnist_img_size)\n",
    "gt_lbl = lbls[0]\n",
    "print(img.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred = jnp.argmax(model.apply(params, np.ravel(img)))\n",
    "print('pred', pred)\n",
    "print('get', gt_lbl)\n",
    "\n",
    "plt_img = img.reshape((28,28))\n",
    "plt.imshow(plt_img); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2629f670-6225-4eb1-86d9-db56e4ffa349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
