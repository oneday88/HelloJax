{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6172ae",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994b9156",
   "metadata": {},
   "source": [
    "在之前的教程里，我们介绍了jax基本语法框架，jax高级自动微分功能(advanced automatic differentiation)并展示了如何用jax搭建一个toy的神经网络框架。\n",
    "在这部分里, 我们尝试用jax搭建一个用于mnist数据集多分类的MLP神经网络模型。具体而言，我们先用熟悉的pytorch的dataloader模块来加载mnist数据集，基于该数据集我们用jax搭建一个MLP模型，对其进行预测及可视化分析。我们之所以在这里使用pytorch的模块，是因为jax的设计与开发人员认为现有的如tensorflow或pytorch自带的dataloader框架已经很成熟了，没有必要在jax里重新造轮子。\n",
    "\n",
    "   1. 通过pytorch的dataloader模块加载mnist数据集，并转成jax可以处理的类型。\n",
    "   2. 设计与搭建MLP网络框架与预测模块。\n",
    "   3. 增加训练模块(training loop)，损失函数(loss function)等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a242bece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import functools\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax import grad, jit, vmap, pmap, random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from typing import Tuple, NamedTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d8d3df",
   "metadata": {},
   "source": [
    "好了，我们实现了第一个基于jax的神经网络模型(虽然很简单)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bc0894-7128-429a-a9a8-c7983820c7cc",
   "metadata": {},
   "source": [
    "## MNIST数据集\n",
    "mnist是计算机视觉(Compute vision)一个经典的新手入门的数据集:\n",
    "   1. 该数据集包含60,000 个训练图片样本与标签, 10,000个测试图片样本与标签。\n",
    "   2. 每张图片的大小是($28\\times28$),也就是每张图片包含$28\\times28=784$向素点\n",
    "在MNIST数据集任务中，我们的目标是给定一个图片，我们预测其是数字[0,1,2,3,4,5,6,7,8,9]中的哪一类,即多分类问题(10个类别)。\n",
    "\n",
    "在pytorch中， 我们可以使用torchvision工具集直接下载:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24de99de-9a65-4c11-85af-3d9e46fd1c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to train_mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 121529806.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train_mnist/MNIST/raw/train-images-idx3-ubyte.gz to train_mnist/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to train_mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 3679252.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train_mnist/MNIST/raw/train-labels-idx1-ubyte.gz to train_mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to train_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 33690368.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to train_mnist/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to train_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 10005529.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to train_mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to test_mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 106181296.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test_mnist/MNIST/raw/train-images-idx3-ubyte.gz to test_mnist/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to test_mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 3407282.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test_mnist/MNIST/raw/train-labels-idx1-ubyte.gz to test_mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to test_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 32014458.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test_mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to test_mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to test_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 11587912.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test_mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to test_mnist/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def custom_transform(x):\n",
    "    return np.ravel(np.array(x, dtype=np.float32))\n",
    "\n",
    "#训练集\n",
    "train_dataset = MNIST('train_mnist',train=True,download=True,transform=None)\n",
    "#测试集\n",
    "test_dataset = MNIST('test_mnist', train=False,download=True,transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2360829a-a32d-411c-b0af-58b644bc13e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "199b72a8-3e10-4f4f-84dc-3e097ee8cad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APAACzBVBJJwAO9dnp/wm8damu6Dw5dRjGf9IKw/+hkVPffCnWNJa7XVNV0Kxa1hErrNe/M2cnYqgElsAHpjkc1wlAODkV694W8c654t8M6n4TuvEctrrFw0cun3c0/lq+3AMJcDK5AyOeTkd+fPvGFn4gsvEtzF4m89tUG1ZJJjuMgUBVYN/EMKOe9YVXtK0bUtdvVs9LsZ7y4YgbIULYycZPoPc8V6lpfwh0/w7p66z8RdXj0y2z8llC4aWQ+mRn8lz9RXPfE3x1pvi46TYaPZTQadpMJghluWDSyrhQM9SMBe5Oc5NcBV7Tda1XRZJJNK1O8sXkG12tZ2iLD0JUjNQ3l9eahN517dT3MvTfNIXb16n6mq9Ff/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVR4AWNgGMyAWUhIqK5jvdSy/9/rQe5kgTlWjs3KRiAYxHsyKfDzxYMgFiOIAALDvfwQBsO/pK8Mz97fhPLAlNDtvyBwbNv3j8jCUHbAnOy/f89yM2jPwiLJwMc4628UqgQTnPvp/0eGFAQXLg5lcO/764YuhuArf3y4IAfmfoQwlBX44e/fckkMYaiA7q6/f6dJ45IViP3zdzcuSQaGn39/OkBl4WEL4euFmLIwXDuETav6lKfAIPy1DYucRNFdUPCe9MOUE3e6CpI6FogZSEKrwbFyOIATQ5v5mkcgXV9auVGlwK4NDGRguL75b88HVDla8QBFF16ADQA8sQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train0 = train_dataset[0]\n",
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff612a46-8138-4b53-8da4-75aa4cf06621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be3a0a5-2490-409b-beba-f221fde5ea35",
   "metadata": {},
   "source": [
    "我们可以看到原始数据里的类型是torchvision.datasets, 我们现在要基于jax的预测模型，我们需要对其进行转换，我们可以用其内置的transform接口, 先将其转成numpy array的形式:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ffb68b0-9ef5-449b-8c65-fb10c9eea6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.ravel: flatten the image 将28x28转成(784,)的一维数据\n",
    "def custom_transform(x):\n",
    "    return np.ravel(np.array(x, dtype=np.float32))\n",
    "\n",
    "#训练集\n",
    "train_dataset = MNIST('train_mnist',train=True,download=True,transform=custom_transform)\n",
    "#测试集\n",
    "test_dataset = MNIST('test_mnist', train=False,download=True,transform=custom_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69368bc2-8db8-400d-a246-4d9e98411c26",
   "metadata": {},
   "source": [
    "上述中，我们通过transform实现了两个功能:\n",
    "   1. 通过np.array将原始pytorch的格式转成了jax可处理的numpy.array的格式。\n",
    "   2. 通过np.ravel将原始28x28的图片转成(784,)的格式。\n",
    "\n",
    "我们接下用torch里的dataloader来构造神经网络训练的数据流, 这里我们设置batch_size=128,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a8c1929-1d15-4753-94d9-8be7b22419a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size=128\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=None, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, collate_fn=None, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4164b67d-8479-40f1-945e-e45e037f4f3e",
   "metadata": {},
   "source": [
    "通过如下代码对数据进行测试，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51663ee9-9767-4169-b058-db6ad9fd5a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([4, 9, 1, 6, 4, 3, 7, 9, 8, 8, 4, 6, 2, 6, 8, 8, 5, 6, 0, 3, 4, 4, 5, 5,\n",
      "        7, 9, 8, 0, 3, 4, 8, 1, 9, 4, 3, 3, 3, 3, 2, 9, 4, 0, 1, 9, 6, 0, 8, 0,\n",
      "        2, 1, 7, 5, 6, 5, 0, 1, 8, 7, 7, 7, 2, 0, 7, 9, 4, 1, 9, 8, 9, 4, 9, 5,\n",
      "        2, 9, 8, 2, 5, 9, 6, 4, 4, 1, 9, 2, 6, 3, 1, 2, 5, 4, 1, 2, 5, 8, 5, 1,\n",
      "        6, 2, 7, 9, 6, 6, 5, 5, 5, 5, 8, 2, 8, 9, 0, 1, 9, 6, 5, 4, 7, 4, 4, 7,\n",
      "        2, 8, 6, 3, 7, 3, 2, 0])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data = next(iter(train_loader))\n",
    "print(batch_data)\n",
    "type(batch_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4749c5cd-9038-4182-be51-f4f1a2c89c01",
   "metadata": {},
   "source": [
    "可以看到，上述数据的格式还是pytorch.tensor的格式(左边是128*784的torch.tensor, 右边是label:长度为128的torch.tensor)。可以通过Dataloader中的collate_fn参数接口对其进行转换:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21e9c96a-d1b6-49a3-a848-e149f38d0abf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    transposed_data = list(zip(*batch))\n",
    "\n",
    "    labels = np.array(transposed_data[1])\n",
    "    imgs = np.stack(transposed_data[0])\n",
    "\n",
    "    return imgs, labels\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False, collate_fn=custom_collate_fn, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2645620c-4911-49dc-9e7d-a0617211cff6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8), array([6, 3, 3, 0, 7, 1, 9, 2, 7, 7, 4, 1, 7, 4, 1, 0, 0, 7, 6, 5, 4, 4,\n",
      "       6, 8, 7, 1, 1, 5, 7, 7, 0, 2, 1, 4, 0, 3, 4, 4, 7, 6, 7, 1, 5, 6,\n",
      "       8, 9, 9, 1, 2, 3, 7, 7, 8, 7, 3, 7, 1, 6, 6, 6, 5, 9, 5, 8, 0, 8,\n",
      "       6, 1, 1, 8, 8, 2, 9, 1, 2, 3, 1, 7, 1, 3, 4, 3, 4, 3, 6, 0, 5, 5,\n",
      "       1, 6, 2, 0, 1, 5, 2, 7, 7, 8, 5, 1, 8, 1, 8, 5, 4, 9, 4, 4, 0, 5,\n",
      "       1, 0, 8, 8, 8, 7, 9, 1, 5, 9, 6, 9, 5, 7, 9, 8, 1, 7]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data = next(iter(train_loader))\n",
    "print(batch_data)\n",
    "type(batch_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a98e7dd-6cee-4fac-9145-b77ee5a89658",
   "metadata": {},
   "source": [
    "## Jax MLP模型框架\n",
    "我们现在基于之前jax与多层感知机(MLP:multi-layer perceptron)搭建一个MLP模型框架。对于mnist,我们现有的每张图片的输入维度是$1\\times 784$,我们要预测是10个类型的概率，相应地，我们可以搭建一个层数分别为[784,512,256,10]的MLP模型框架:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc8ecbb6-02be-4eee-9f49-ca39fa238816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_MLP(layer_widths):\n",
    "    params = []\n",
    "    for in_width, out_width in zip(layer_widths[:-1], layer_widths[1:]):\n",
    "        params.append([\n",
    "            np.random.randn(out_width, in_width),# the weight\n",
    "            np.random.randn(out_width,) # the bias\n",
    "        ])\n",
    "    return params\n",
    "\n",
    "MLP_params = init_MLP([784, 512, 256, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecdfdcc-9c29-411b-b29c-a435d46ee178",
   "metadata": {},
   "source": [
    "对于设计好的参数，我们可以用之前学习过的tree_map函数打印；确认该函数框架和我们希望的是一致的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ab94b05-6355-478a-8428-b793973ccea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(512, 784), (512,)], [(256, 512), (256,)], [(10, 256), (10,)]]\n"
     ]
    }
   ],
   "source": [
    "print(jax.tree_map(lambda x: x.shape, MLP_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c27c6f6-acfb-4fc5-a0a0-580379f1425c",
   "metadata": {},
   "source": [
    "对于该框架，存在着一些问题: 我们通过np.random.randn的模型参数默认是N(0,1)，对于如此大的参数，我们通过backpropagation可能会遇到梯度爆炸(Gradient explosion)等问题:\n",
    "   1. 在开始尝试新的高大上的初始始化方法前，我们简单对其进行缩放(*0.1, *0.01)等。\n",
    "   2. 基于先前对随机数生成机制的介绍，对于神经网络模型的函数或类:我们需要显式地赋予一个状态变量。对于一个MLP模型，理论上，每一层layer我们都需要显式地赋予一个状态变量，我们可以用之前介绍的random.split的机制实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e80a232d-dcc7-4332-bec6-0bc0d1ff885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_MLP(layer_widths,parent_key, scale=0.01):\n",
    "    params = []\n",
    "    keys = jax.random.split(parent_key, num=len(layer_widths)-1)\n",
    "    for in_width, out_width,key in zip(layer_widths[:-1], layer_widths[1:],keys):\n",
    "        weight_key, bias_key = jax.random.split(key)\n",
    "        params.append([\n",
    "            scale*jax.random.normal(weight_key, shape=(out_width, in_width)),# the weight\n",
    "            scale*jax.random.normal(bias_key, shape=(out_width,)) # the bias\n",
    "        ])\n",
    "    return params\n",
    "\n",
    "seed=0\n",
    "key = jax.random.PRNGKey(seed)\n",
    "MLP_params = init_MLP([784, 512, 256, 10],key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2059a6-7f86-458f-ac3f-0efea7c7a255",
   "metadata": {},
   "source": [
    "### 预测模块:交叉熵损失与log-sum-exp trick\n",
    "我们接下来跟进预测模块的代码, 在开始前我们介绍一下机器学习分类任务常见的log-sum-exp trick。\n",
    "对于神经网络解决多分类问题(假设我们有K个类别), 一种常用的方式是在最后一层通过softmax将预测的K个类别的值$x_j$映射至$[0,1]$区间,用公式表示:\n",
    "$$\n",
    "Pr(G=j|X)=\\frac{exp(x_j)}{\\sum\\limits_{i=1}^K exp(x_i)}\n",
    "$$\n",
    "对于分类问题，常用的loss function是交叉熵损失(cross-entropy loss),即对上述每个预测的概率取对数，即有:\n",
    "$$\n",
    "log(\\frac{exp(x_j)}{\\sum\\limits_{i=1}^K exp(x_i)}) =  log(exp(x_j)) - log(\\sum\\limits_{i=1}^K exp(x_i)) = x_j-log(\\sum\\limits_{i=1}^K exp(x_i))\n",
    "$$\n",
    "也就对于cross-entropy loss,我们可以直接用每个类别中间预测值$x_j$减去其所有的类别array的log-sum-exp的映射结果。\n",
    "在实现中，对于log-sum-exp操作，scipy.special里调用logsumexp函数，在jax里,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f16accd7-2a57-4ec9-bb26-e0a28163a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.special import logsumexp\n",
    "from jax.scipy.special import logsumexp\n",
    "def MLP_predict(params, x):\n",
    "    hidden_layers = params[:-1]\n",
    "    activation = x\n",
    "    for w,b in hidden_layers:\n",
    "        activation = jax.nn.relu(jnp.dot(w,activation)+b)\n",
    "\n",
    "    #在最后一层，我们不想使用relu激活函数\n",
    "    w_last,b_last = params[-1]\n",
    "    logits = jnp.dot(w_last, activation)+b_last\n",
    "    \n",
    "    return  logits - logsumexp(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575fad1e-0ed7-44b3-a34d-6069b26b5fe7",
   "metadata": {},
   "source": [
    "随机生成一个图片的shape的随机样本对上述进行测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee59f060-08e4-4601-9572-434f27a12eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "# test single example\n",
    "mnist_img_size = (28, 28)\n",
    "dummy_img_flat = np.random.randn(np.prod(mnist_img_size))\n",
    "print(dummy_img_flat.shape)\n",
    "\n",
    "prediction = MLP_predict(MLP_params, dummy_img_flat)\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a84fe7c-04c1-4a44-b84b-0d6cd967f4f7",
   "metadata": {},
   "source": [
    "同时对16张(一个batch里的)图片进行预测测试:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95bd183e-2745-420f-bd4f-fc3089245bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 784)\n",
      "(16, 10)\n"
     ]
    }
   ],
   "source": [
    "# test batched function\n",
    "batched_MLP_predict = vmap(MLP_predict, in_axes=(None, 0))\n",
    "\n",
    "dummy_imgs_flat = np.random.randn(16, np.prod(mnist_img_size))\n",
    "print(dummy_imgs_flat.shape)\n",
    "predictions = batched_MLP_predict(MLP_params, dummy_imgs_flat)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc91945-8570-4c99-82e6-ac15ed1d7ef8",
   "metadata": {},
   "source": [
    "#### training loop and evaluation\n",
    "在开始这部分之前，我们介绍一下one-hot-embedding, 对于mnist数据集，假设我们有如下5个label向量:[0,2,4,6,8],我们可以将其表示成5*10(10表示类别总数),其one-hot embedding可以表示如下:\n",
    "\n",
    "$$label = \n",
    "\\begin{bmatrix}\n",
    "\\begin{array}{c}\n",
    "    0  \\\\\n",
    "    2 \\\\\n",
    "    4\\\\\n",
    "    6\\\\\n",
    "    8 \n",
    "\\end{array}\n",
    "\\end{bmatrix} \\Longrightarrow \n",
    "\\begin{bmatrix}\n",
    "\\begin{array}{cccccccccc}\n",
    "     1 & 0& 0 &0 & 0 & 0 & 0 &0 & 0 & 0  \\\\\n",
    "     0 & 0& 1 &0 & 0 & 0 & 0 &0 & 0 & 0  \\\\\n",
    "     0 & 0& 0 &0 & 1 & 0 & 0 &0 & 0 & 0 \\\\\n",
    "     0 & 0& 0 &0 & 0 & 0 & 1 &0 & 0 & 0 \\\\\n",
    "     0 & 0& 0 &0 & 0 & 0 & 0 &0 & 1 & 0  \n",
    "\\end{array}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "也就是若其第label为k, 其第k列下标为1，其余都为0.\n",
    "在jax中，我们可以通过 jax.nn.one_hot实现one-hot embedding。相应地，我们可以实现一个简单的基于cross-entropy loss的神经网络训练loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c887013c-19f3-4fc7-aa8b-d372a918bf57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transfer the data to jnp\n",
    "# optimization - loading the whole dataset into memory\n",
    "train_images = jnp.array(train_dataset.data).reshape(len(train_dataset), -1)\n",
    "train_lbls = jnp.array(train_dataset.targets)\n",
    "\n",
    "test_images = jnp.array(test_dataset.data).reshape(len(test_dataset), -1)\n",
    "test_lbls = jnp.array(test_dataset.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6980f88f-fb04-40e2-b428-8a0b9af1e242",
   "metadata": {},
   "source": [
    "#### 损失函数(loss function)与准确度(accuracy)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9d1a3c4-8fb2-468d-850a-ec82502657db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(params, imgs, gt_lbls):\n",
    "    predictions = batched_MLP_predict(params, imgs)\n",
    "\n",
    "    return -jnp.mean(predictions * gt_lbls)\n",
    "\n",
    "def accuracy(params, dataset_imgs, dataset_lbls):\n",
    "    pred_classes = jnp.argmax(batched_MLP_predict(params, dataset_imgs), axis=1)\n",
    "    return jnp.mean(dataset_lbls == pred_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6978974-1e63-48dc-9662-d968bc040bbb",
   "metadata": {},
   "source": [
    "Training loop,我们这里使用jax中的value_and_grad同时输入函数的loss function与gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059b5bef-669f-4b4b-a39f-256c10b878c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;129m@jit\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(params, imgs, gt_lbls, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m):\n\u001b[1;32m      3\u001b[0m     loss, grads \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(loss_fn)(params, imgs, gt_lbls)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, jax\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m p, g: p \u001b[38;5;241m-\u001b[39m lr\u001b[38;5;241m*\u001b[39mg, params, grads)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'jit' is not defined"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def update(params, imgs, gt_lbls, lr=0.01):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params, imgs, gt_lbls)\n",
    "    return loss, jax.tree_map(lambda p, g: p - lr*g, params, grads)\n",
    "\n",
    "num_epochs = 10\n",
    "# Create a MLP\n",
    "MLP_params = init_MLP([np.prod(mnist_img_size), 512, 256, len(MNIST.classes)], key)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for cnt, (imgs, lbls) in enumerate(train_loader):\n",
    "        gt_labels = jax.nn.one_hot(lbls, len(MNIST.classes))\n",
    "        \n",
    "        loss, MLP_params = update(MLP_params, imgs, gt_labels)\n",
    "        \n",
    "        if cnt % 50 == 0:\n",
    "            print(loss)\n",
    "\n",
    "    print(f'Epoch {epoch}, train acc = {accuracy(MLP_params, train_images, train_lbls)} test acc = {accuracy(MLP_params, test_images, test_lbls)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a677f30b-9a4f-43ee-b904-dfb74cb84ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, lbls = next(iter(test_loader))\n",
    "img = imgs[0].reshape(mnist_img_size)\n",
    "gt_lbl = lbls[0]\n",
    "print(img.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pred = jnp.argmax(MLP_predict(MLP_params, np.ravel(img)))\n",
    "print('pred', pred)\n",
    "print('gt', gt_lbl)\n",
    "\n",
    "plt.imshow(img); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
